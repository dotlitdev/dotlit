# Fuzzy text search

Related

- [[testing/compact_manifest]]

## Fuse.js

https://fusejs.io/

https://dev.to/noclat/using-fuse-js-with-react-to-build-an-advanced-search-with-highlighting-4b93

```js !collapse #intro
return (async (fn) => {
  const { default: Fuse } = await import(
    "https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.esm.js"
  );
  const manifest = await fetch("/manifest.json").then((res) => res.json());
  const fuse = new Fuse(manifest.nodes, {
    includeScore: true,
    keys: ["title", "id"],
  });

  // 3. Now search!
  return fuse.search("../../..",{limit:5});
})();

```
```js !plugin !collapse type=repl of=search
export const repl = async (src, meta) => {
  const t = Date.now();

  const { default: Fuse } = await import(
    "https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.esm.js"
  );
  // const manifest = await fetch("/manifest.json").then((res) => res.json());

  const fullLocal = await (async (fn) => {
    const path = lit.utils.path;
    const all = [];
    const visit = async (root) => {
      try {
        const list = await lit.fs.readdir(root);
        return Promise.all(
          list.map(async (key) => {
            const pathname = path.join(root, key);
            const stat = await lit.fs.stat(pathname);
            let contents;
            if (key === ".git" || !key) {
            } else if (stat.type === "dir") await visit(pathname);
            else if (pathname.endsWith(".lit"))
              contents = await lit.fs.readFile(pathname, {
                encoding: "utf8",
                localOnly: true,
              }); //.slice(0,10);
            const item = { pathname, type: stat.type, contents };
            all.push(item);
            return item;
          })
        );
      } catch (err) {
        alert(err.message);
      }
    };

    await visit("/");
    return all;
  })();

  // return fullLocal

  const fuse = new Fuse(fullLocal, {
    ignoreLocation: true,
    includeScore: true,
    includeMatches: true,
    ignoreFieldNorm: true,
    minMatchCharLength: 4,
    keys: ["pathname", "contents"],
  });

  // 3. Now search!
  const query = src.trim();
  const msg = `Results for search "**${query}**". In **${
    (Date.now() - t) / 1000
  }** seconds.\n\n`;

  return (
    msg +
    fuse
      .search(query, { limit: 10 })
      //.map(x=>x.matches.map(x=>x.indices))
      .map((x) => [x.score, x.item.pathname, x.refIndex, x.matches])
      .map(
        ([score, pathname, index, matches]) => `1. [${pathname}](${pathname}) `
      )
      .join("\n")
  );
};

```
```js search.jsx !plugin !collapse type=viewer Babel=true of=search2
import Fuse from "https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.esm.js";
export const viewer = ({ node, React }) => {

  const {useEffect,useState} = React
  const [msg, setMsg] = useState('Searching...')
  // const manifest = await fetch("/manifest.json").then((res) => res.json());

  // Recursively builds JSX output adding `<mark>` tags around matches
  const highlight = (value, indices = [], i = 1) => {
    const pair = indices[indices.length - i];
    return !pair ? (
      value
    ) : (
      <>
        {highlight(value.substring(0, pair[0]), indices, i + 1)}
        <mark>{value.substring(pair[0], pair[1] + 1)}</mark>
        {value.substring(pair[1] + 1)}
      </>
    );
  };

  const fullLocal = async (fn) => {
    const path = lit.utils.path;
    const all = [];
    const visit = async (root) => {
      try {
        const list = await lit.fs.readdir(root);
        return Promise.all(
          list.map(async (key) => {
            const pathname = path.join(root, key);
            const stat = await lit.fs.stat(pathname);
            let contents;
            if (key === ".git" || !key) {
            } else if (stat.type === "dir") await visit(pathname);
            else if (pathname.endsWith(".lit"))
              contents = await lit.fs.readFile(pathname, {
                encoding: "utf8",
                localOnly: true,
              }); //.slice(0,10);
            const item = { pathname, type: stat.type, contents };
            all.push(item);
            return item;
          })
        );
      } catch (err) {
        alert(err.message);
      }
    };

    await visit("/");
    return all;
  };

  // return fullLocal

  useEffect(async fn => {
     const t = Date.now();
const fuse = new Fuse(await fullLocal(), {
    ignoreLocation: true,
    includeScore: true,
    includeMatches: true,
    ignoreFieldNorm: true,
    minMatchCharLength: 4,
    keys: ["pathname", "contents"],
  });

  // 3. Now search!
  const query = node.data.value.trim();

  return (
    <div>
      <span>{msg}</span>
    </div>
  );
};

```



```text repl=search > md
test
```
```>txt attached=true updated=1621893609981
Results for search "**test**". In **0.069** seconds.

1. [/testing/lightningfs.lit](/testing/lightningfs.lit) 
   �
      > [{"indices":[[1,4]],"value":"/testing/lightningfs.lit","key":"pathname"},{"indices":[[242,245],[320,323],[1883,1886],[1988,1991],[2021,2024],[2324,2327],[2439,2442],[2477,2480],[3500,3503],[3710,3713],[3749,3752],[4112,4115],[4875,4878],[4885,4888],[4907,4910],[5030,5033],[5112,5115],[5123,5126],[6128,6131],[6176,6180],[6188,6191],[6222,6225],[6234,6237],[6610,6614],[6630,6633],[6669,6673],[6688,6691],[6854,6857],[7002,7005],[7099,7102],[7198,7201],[8272,8275],[9011,9014],[9111,9114],[9122,9125],[9203,9206],[9604,9607],[9699,9702],[10046,10049],[11542,11545],[11551,11554],[11739,11742],[12812,12815],[12880,12883],[12939,12942],[13009,13012],[13018,13021],[13156,13159],[13272,13275],[13522,13525],[13640,13643],[13748,13751],[13953,13956]],"value":"# Lightning FS\n\nhttps://github.com/isomorphic-git/lightning-fs\n\n## Table of Contents\n\n## Bugs 🐜\n\n- [x] wikiLinks and 404 behaviour results in incorrect/dangling lfs due to incorrect baseUrl.\n\n## Tour of the API\n```js\nreturn lit.fs.readdir('/testing/log')\n```\n\n```js > json !collapse\nreturn lit.lfs.promises.writeFile('/testing/data.json', \"{}\", {encoding: 'utf8'})\n```\n```>json !collapse attached=true updated=1621193177415\nnull\n```\n\n```js > json !collapse\nreturn lit.fs.readFile('/doesntexist.json')\n```\n```js > json !collapse\nreturn lit.fs.readStat('/manifest.json')\n```\n\n```js > json !collapse\nreturn lit.fs\n          .readStat('/manifest.json')\n          .then(stat => [!!stat.local.value, !!stat.remote.value])\n```\n```>json !collapse attached=true updated=1619878321018\n[ true, false ]\n```\n```js > json !collapse\nreturn lit.fs\n          .stat('/notfound')\n          .catch(s => \"404 Not Found\")\n```\n```>json !collapse attached=true updated=1621124612430\n404 Not Found\n```\n```js > json !collapse\nreturn lit.fs\n          .stat('/index.lit')\n          .then(stat => stat)\n```\n```>json !collapse attached=true updated=1619878403441\n{ type: 'file',\n  mode: 438,\n  size: 4589,\n  ino: 6,\n  mtimeMs: 1619686223652,\n  ctimeMs: 1619686223652,\n  uid: 1,\n  gid: 1,\n  dev: 1 }\n```\n```js > diff !collapse\n// https://github.com/kpdecker/jsdiff\nconst {root,src} = lit.location\nconst {join} = lit.utils.path\nconst filename = join(root,src)\n\nconst withStats = async stats => {\n  const cp = lit.utils.diff.createPatch\n  // const f = \n  const local = stats.local.value\n  const remote = stats.remote.value\n  const patch = cp(filename, local, remote)\n  console.log(patch.split('\\n').map(l=>'    '+l).join('\\n'))\n  return \"logged patch\"\n}\n\nconst stats = lit.fs.readStat(filename, {encoding: 'utf8'})\nreturn stats.then(withStats)\n```\n```>diff !collapse attached=true updated=1620338765234\n    Index: /testing/lightningfs.lit\n    ===================================================================\n    --- /testing/lightningfs.lit\n    +++ /testing/lightningfs.lit\n    @@ -1697,13 +1697,57 @@\n     \n     const stats = lit.fs.readStat(filename, {encoding: 'utf8'})\n     return stats.then(withStats)\n     ```\n    -```>diff !collapse attached=true updated=1620338750310\n    +```>diff !collapse attached=true updated=1620338108145\n         Index: /testing/lightningfs.lit\n         ===================================================================\n         --- /testing/lightningfs.lit\n         +++ /testing/lightningfs.lit\n    +    @@ -1680,34 +1680,31 @@\n    +       dev: 1 }\n    +     ```\n    +     ```js > diff !collapse\n    +     // https://github.com/kpdecker/jsdiff\n    +    -const {root,src} = lit.location\n    +    -const {join} = lit.utils.path\n    +    -const filename = join(root,src)\n    +    +const filename = '/index.lit'\n    +     \n    +     const withStats = async stats => {\n    +       const cp = lit.utils.diff.createPatch\n    +    -  // const f = \n    +    +  // const f = lit.location.src\n    +       const local = stats.local.value\n    +       const remote = stats.remote.value\n    +       const patch = cp(filename, local, remote)\n    +    -  console.log(patch.split('\\n').map(l=>'    '+l).join('\\n'))\n    +    +  // console.log(patch)\n    +       return \"logged patch\"\n    +     }\n    +     \n    +     const stats = lit.fs.readStat(filename, {encoding: 'utf8'})\n    +     return stats.then(withStats)\n    +     ```\n    +    -```>diff !collapse attached=true updated=1620337567383\n    +    -Index: /testing/lightningfs.lit\n    +    +```>text !collapse attached=true updated=1620336678219\n    +    +Index: /index.lit\n    +     ===================================================================\n    +    ---- /testing/lightningfs.lit\n    +    -+++ /testing/lightningfs.lit\n    +    -@@ -1680,26 +1680,24 @@\n    +    -   dev: 1 }\n    +    - ```\n    +    +--- /index.lit\n    +    ++++ /index.lit\n    +     \n    +    +logged patch\n    +    +```\n    +     \n    +     \n    +     ```>fs ls=/\n    +     \n         \n     logged patch\n     ```\n     \n    \nlogged patch\n```\n```js #delete !localonly\nconst path = \"/throwaway/test.txt\"\nconsole.log(ast)\nreturn lit.fs.writeFile(path, \"content\", {\n  encoding: 'utf8',\n  localOnly: true\n})\n```\n```>txt attached=true updated=1621257066210\n{ type: 'element',\n  tagName: 'cell',\n  properties: { class: 'cell' },\n  children: \n   [ { type: 'element',\n       tagName: 'pre',\n       properties: {},\n       children: [Object],\n       position: [Object] },\n     { type: 'element',\n       tagName: 'pre',\n       properties: {},\n       children: [Object],\n       position: [Object] } ],\n  position: \n   { start: { line: 155, column: 1, offset: 51462 },\n     end: { line: 177, column: 4, offset: 52007 } } }\nundefined\n```\n\n\n\n\n\n## Plugins \n\n### `fs` plugin\n\n```js\nreturn lit.utils.momento\n```\n```>txt attached=true updated=1621257612846\n{ MsToRelative: [Getter], DatesToRelativeDelta: [Getter] }\n```\n\n\n```jsx fsviewer.jsx babel=true !plugin of=fs !collapse\nexport const viewer = ({node, React}) => {\n  const {useState, useEffect} = React\n  const {join,extname} = lit.utils.path\n  const [src, setSrc] = useState(node?.data?.value?.trim())\n  const meta = node?.properties?.meta || {}\n\n  const styles = {\n    dir: {fontWeight: \"bold\"},\n    '.lit': {color: 'blue'},\n  }\n  const getType = s => {\n    const [filepath,stat] = s\n    if (stat.type === 'file') {\n      return extname(filepath)\n    }\n    return stat.type\n  }\n\n  const Stat = (props) => {\n    const stat = props?.stat || {}\n    if (stat.message) return <div>{stat.message}</div>\n    return <div>\n      <div style={{marginBottom: '0.4em'}}>Type: <span>{stat.type}</span> mtime: <span>{lit.utils.momento.MsToRelative(stat.mtimeMs - Date.now())}</span> Size: <span>{(props.size / 1024).toFixed(2)} KB</span></div>\n      \n      {stat.contents && stat.contents.map( l => {\n      const name = l[0]\n      const path = join(props.src,name)\n      const type = getType(l)\n      const style = styles[type] || null\n      return <div><span onClick={ev=> props.select(path)} style={style}>{name}</span></div>\n     })}\n    </div>\n  }\n\n  const [content, setContent] = useState(<span>loading...</span>)\n  const [stat, setStat] = useState(undefined)\n  const [size, setSize] = useState(null)\n\n  useEffect(async fn => {\n    let stat, size\n    try {\n      stat = await lit.fs.stat(src)\n      size = await lit.fs.du(src)\n      if (stat.type === 'dir') {\n          const list = await lit.fs.readdir(src)\n          const withStats = list.map( async l => [l,await lit.fs.stat(join(src,l))])\n          stat.contents = await Promise.all(withStats)\n      }\n      setStat(stat)\n      setSize(size)\n    } catch(err) {\n      setStat(err)\n      setSize(null)\n    }\n  }, [src])\n\n  const bigger = {fontSize: '1em', width: '100%'}\n  return <div style={bigger}>\n     <input style={bigger} value={src} onChange={ev=>setSrc(ev.target.value)}/>\n     <div style={{fontFamily: 'monospace', marginBottom: '0.4em'}}>\n     <Stat src={src} stat={stat} size={size} select={setSrc}/>\n     {!stat && content}\n     </div>\n     <button disabled={src === '/'} onClick={ev=>  setSrc(src.split('/').slice(0,-1).join('/') || '/')}>Back</button>\n     {stat && <button disabled>Reset</button>}\n     {stat && <button onClick={ev=> confirm(\"Are you sure you want to delete \" + src) && lit.fs.unlink(src)}>Delete</button>}\n     {stat && <button disabled>Diff</button>}\n    </div>\n}\n```\n\n```>fs\n/\n```\n\n### Finder (local fs)\n\n```js !collapse > json\nconst path = lit.utils.path;\nconst visit = async (root) => {\n  const list = await lit.fs.readdir(root);\n  return Promise.all(\n    list.map(async (key) => {\n      const pathname = path.join(root, key);\n      const stat = await lit.fs.stat(pathname);\n      let contents;\n      if (key === \".git\" || !key) {\n        return { key, root,pathname, type: stat.type };\n      } else if (stat.type === \"dir\") {\n        // alert(\"Traversing \" + pathname);\n        contents = await visit(pathname);\n      } else\n        contents =\n          (\n            await lit.fs.readFile(pathname, {\n              encoding: \"utf8\",\n              localOnly: true,\n            })\n          ).slice(0, 10) + \"...\";\n      return { pathname, type: stat.type, contents };\n    })\n  );\n};\n\nreturn (async (fn) => {\n  lit.fs.writeFile(\n    \"/testing/full.json\",\n    JSON.stringify(await visit(\"/\"), null, 2)\n  );\n})();\n\n```\n```>json attached=true updated=1621861533762\nundefined\n```\n\n```json2 !inline < full.json\n\n\n```\n\n\n### Finder (from manifest)\n\n\n```js !plugin type=viewer !collapse of=search\nconst sortBy = (keys) => (a, b) => {\n  for (const key of keys) {\n    if (a[key] !== b[key]) break;\n    else return a[key] > b[key] ? 1 : -1;\n  }\n};\n\nconst itemBuilder = (React) => (item) => {\n  const rc = React.createElement;\n  return rc(\n    \"li\",\n    { className: \"item\" },\n    rc(\n      \"a\",\n      { href: lit.href || lit.location.root + item.id },\n      item.title || item.id\n    )\n  );\n};\n\nexport const viewer = ({ node, React }) => {\n  const rc = React.createElement;\n  const { useState, useEffect } = React;\n  const meta = node.properties && node.properties.meta;\n  const [src, setSrc] = useState(meta.search || node.data.value.trim());\n  const [content, setContent] = useState(\"Loading...\");\n  const item = itemBuilder(React);\n\n  useEffect(async () => {\n    const resp = await fetch(\"/manifest.json\");\n    const json = await resp.json();\n    let regex;\n    try {\n      regex = new RegExp(src, \"i\");\n    } catch (err) {}\n    const res = json.nodes\n      .map((x) => x)\n      .filter((x) => {\n        return (\n          x.id.indexOf(src) >= 0 ||\n          (regex && regex.test(x.id)) ||\n          (x.title &&\n            (x.title.indexOf(src) >= 0 || (regex && regex.test(x.title))))\n        );\n      })\n      .sort()\n      .map((x) => item(x));\n    //.join(\"\\n\")\n    setContent(rc(\"ol\", null, res));\n  }, [src]);\n\n  return rc(\n    \"div\",\n    {\n      className: \"custom-react-view\",\n    },\n    [\n      rc(\"input\", {\n        style: { width: \"100%\", fontSize: \"1.2em\" },\n        value: src,\n        onChange: (e) => setSrc(e.target.value),\n      }),\n      content,\n    ]\n  );\n};\n\n```\n```>search\nG.*hUb\n```\n## Sync `local|remote|origin`\n\n\n```js #sync !collapse\n// fetch all remote files and store\n// locally if they don't already exist \n\n\nreturn (async fn => {\n  const t = Date.now()\n  const p = lit.utils.path\n  const writePLocal = async (...args) => {\n    \n  }\n\n  const m = await fetch('/manifest.json')\n                  .then(res => res.json())\n                  .catch(e=>({nodes:[]}))\n\n  const duds = []\n  const synced = []\n  const errors = []\n  const res = await Promise.all(m.nodes.map( async n => {\n    try {\n    n.stats = await lit.fs.readStat(n.id)\n      .then(x=>x)\n      .catch(err=>{\n          duds.push(n.id)\n          return {local: {}, remote: {}}\n      })\n\n    if (!n.stats.local.stat && n.stats.remote.stat) {\n        await lit.fs.writeFile(n.id, n.stats.remote.value, {localOnly: true, encoding: 'utf8'})\n        synced.push(n)\n    }\n    \n    return n\n    } catch(err) {errors.push(n.id + \" : \" + err.message)} \n  } ))\n  console.log(`Synced ${synced.length}/${m.nodes.length} files in ${(Date.now() - t)/1000} seconds. Duds: ${duds.length} Errors: ${errors.length}`)\n  return {duds, errors}\n})()\n\n```\n```>txt attached=true updated=1621892351482\nSynced 0/189 files in 0.407 seconds. Duds: 30 Errors: 2\n{ duds: \n   [ 'transfomers.lit',\n     'custom-module.mjs',\n     'log/checkforinput.js',\n     'agora.lit',\n     'components.lit',\n     'rk.jsx',\n     'viewers.lit',\n     'litconfig.lit',\n     'testing/getserviceworker--sw',\n     'fsviewer.jsx',\n     'worker2.js',\n     'wikilinks.lit',\n     '.github/workflows/generate.yaml',\n     'renderer/file.txt',\n     'utils/urifragments.lit',\n     '/testing/log/2021-w22.lit',\n     'worker.js',\n     'meta/.github/workflows/npm-publish.yaml',\n     'meta/files_and_links.lit',\n     'viewers/meta.js',\n     'utils/fs.lit',\n     'distributed_knowledge_graph.lit',\n     'markdown.lit',\n     'runkit-repl-endpoint.js',\n     'experimental_social_network.lit',\n     'log/today.js',\n     'filename',\n     'remark.lit',\n     'gitworker.js',\n     'unified.lit' ],\n  errors: \n   [ '../scratch_pad.lit#viewers : Unable to normalize path - traverses above root directory',\n     '../serviceworker.js : Unable to normalize path - traverses above root directory' ] }\n```\n```>txt  updated=1621257192205\nSynced 90/139 files in 0.616 seconds. Duds: 30 Errors: 7\n{ duds: \n   [ 'remark.lit',\n     'viewers.lit',\n     '.github/workflows/generate.yaml',\n     'components.lit',\n     'utils/urifragments.lit',\n     'articles/ideas.lit',\n     'executing_code_cells.lit',\n     './runkit-repl-endpoint.js',\n     'transfomers.lit',\n     'fsviewer.jsx',\n     'viewers/meta.js',\n     'filename',\n     'worker.js',\n     'worker2.js',\n     '../../../../../testing/log/2021-05.lit',\n     'utils/fs.lit',\n     '../../../../../testing/log/2021.lit',\n     'rk.jsx',\n     '../../../../../testing/log/2021-05',\n     'wikilinks.lit',\n     'unified.lit',\n     'testing/getserviceworker--sw',\n     'meta/.github/workflows/npm-publish.yaml',\n     'renderer/file.txt',\n     'markdown.lit',\n     '../../../../../testing/log/year.lit',\n     'log/today.js',\n     'log/checkforinput.js',\n     'litconfig.lit',\n     '../../../../../testing/log/2021' ],\n  errors: \n   [ '../scratch_pad.lit#viewers : Unable to normalize path - traverses above root directory',\n     '../components/components.lit : Unable to normalize path - traverses above root directory',\n     '../../../../../meta/settings.lit#plantuml-viewer--repl : Unable to normalize path - traverses above root directory',\n     '../../../../../testing/log/2021-w20.lit : Unable to normalize path - traverses above root directory',\n     '../../../../../testing/log/2021-05-12.lit : Unable to normalize path - traverses above root directory',\n     '../utils/git-commit-all.js : Unable to normalize path - traverses above root directory',\n     '../../../../../testing/log/2021-w21.lit : Unable to normalize path - traverses above root directory' ] }\n```\n\n\n\n\n## Emergency wipe ⚠️\n\n```>md !warn\nClicking on the following link will prompt you to confirm you want to wipe the local file system!\n```\n\n[WIPE ⚠️](?__lfs_wipe=true)\n\n","key":"contents"}]
1. [/testing/isomorphic_git.lit](/testing/isomorphic_git.lit) 
   �
      > [{"indices":[[1,4]],"value":"/testing/isomorphic_git.lit","key":"pathname"},{"indices":[[47,50],[2058,2061],[2149,2152],[2794,2797],[2964,2967],[3210,3213],[3450,3453],[3493,3496],[3538,3541],[3580,3583],[3625,3628],[3670,3673],[3715,3718],[3760,3763],[3805,3808],[3848,3851],[3895,3898],[3934,3937],[3984,3987],[4021,4024],[4505,4508],[5640,5643],[5755,5758],[5856,5859],[6006,6009],[6027,6030],[6056,6059],[6122,6125],[6237,6240],[6306,6309],[6423,6426],[6492,6495],[12441,12444]],"value":"# Isomorphic Git\n\n\nSince `.lit` already uses [[testing/LightningFS]] for the local filesystem we can easily use https://isomorphic-git.org/docs/en/quickstart to manage versioning...\n\n## Table of Contents\n\n## Initial plan\n\nThe initial plan is to just auto commit on all actions, enabling \"infinite\" undo.\n\nThereafter that may remain the default but ideally an ergonomic version of the raw git api can be exposed for more advanced users.\n\n*Implementation*\n\n\n\n\n\n```js ../utils/git-commit-all.js !plugin type=fn id=git-commit-all !collapse\n// initially, because it's on every change \n// a commit will mostly be for a single\n// file at a time the immediate exception \n// being when a file with output files \n// is edited, in which case the commit \n// includes those files.\n\nexport const fn = async () => {\n  const now = (new Date()).toISOString()\n\n  const fs = lit.lfs \n  const dir = lit.location.root\n  const git = lit.git\n  const FILE = 0, WORKDIR = 2, STAGE = 3\n\n  const unstaged = row => {\n    return row[WORKDIR] !== row[STAGE]\n  }\n\n  // get/list unstaged files\n  const status = await git.statusMatrix({ fs,dir})\n  const files = status\n                .filter( unstaged )\n                .map(row => row[FILE])\n\n  // stage everything\n  await git.add({fs, dir, filepath: '.'})\n\n  // message \n  const message = `Commit ${lit.location.src}\n\nat ${now} includes the following ${files.length} files:\n${files.map(f=> \"- \" + f).join('\\n')}`\n\n  // return message\n\n  // commit\n  const sha = await git.commit({fs, dir,\n    message,\n    author: {\n      name: 'dotlitbot',\n      email: 'bot@dotlit.org'\n    }\n  })\n  return `Committed ${sha.slice(0,6)} \n${message}`\n}\n```\n```js !plugin id=git type=menu !collapse\nexport const menu = (ctx, {React, Menu}) => {\n  const rc = React.createElement\n  const commit = lit.file.data.plugins.fn['git-commit-all']\n  const onClick = async ev => alert(await commit())\n  return rc( Menu, {\n    title:\"Git\",\n    disabled: false,\n  }, [rc('span', {onClick}, 'Commit All')])\n}\n```\n```txt updated=1619425559711\nCommitted d738da \nAuto commit testing/isomorphic_git.lit\n\nat: 2021-04-26T08:25:54.893Z\nincludes the following 2 files:\n- testing/isomorphic_git.lit\n- utils/git-commit-all.js\n```\n## Investigating API\n\n\n```js\nreturn lit.fs\n       .readFile('/.git/HEAD', {\n          encoding: 'utf8'\n        })\n```\n```>txt attached=true updated=1621327741152\nref: refs/heads/master\n\n```\n```js\nreturn (async () => {\n  return await lit.git.init({\n    fs: lit.lfs, \n    dir: lit.location.root\n  })\n})()\n```\n```>txt attached=true updated=1621327753489\nundefined\n```\n### Status\n\n```js\nreturn (async () => {\n  return lit.location.src + \" : \" + await lit.git.status({\n    fs: lit.lfs, \n    dir: lit.location.root, \n    filepath: '.' \n  })\n})()\n```\n```>txt attached=true updated=1621335274603\ntesting/isomorphic_git.lit : *added\n```\n```js\nreturn (async () => {\n  return await lit.git.statusMatrix({\n    fs: lit.lfs, \n    dir: lit.location.root, \n    filepaths: ['testing/']\n  })\n})()\n```\n```>txt attached=true updated=1621123831529\n[ [ '<', 1, 0, 1 ],\n  [ 'articles/ideas_for.lit', 1, 1, 1 ],\n  [ 'execute_code_cells.lit', 1, 1, 1 ],\n  [ 'index.lit', 1, 1, 1 ],\n  [ 'log/2021-05-11.lit', 1, 1, 1 ],\n  [ 'meta/settings.lit', 1, 1, 1 ],\n  [ 'parser/parser.lit', 1, 1, 1 ],\n  [ 'plugin_system.lit', 1, 1, 1 ],\n  [ 'renderer/renderer.lit', 1, 1, 1 ],\n  [ 'renderer/viewers', 1, 0, 1 ],\n  [ 'repls.lit', 1, 1, 1 ],\n  [ 'scratch_pad.lit', 1, 1, 1 ],\n  [ 'testing/input_buffer.lit', 1, 1, 1 ],\n  [ 'testing/isomorphic_git.lit', 1, 1, 1 ],\n  [ 'testing/lightningfs.lit', 1, 1, 1 ],\n  [ 'testing/log/2021-05-09.lit', 1, 1, 1 ],\n  [ 'testing/log/2021-05-11.lit', 1, 1, 1 ],\n  [ 'testing/log/2021-05-12.lit', 1, 1, 1 ],\n  [ 'testing/log/2021-05-13.lit', 1, 1, 1 ],\n  [ 'testing/log/2021-05-15.lit', 1, 1, 1 ],\n  [ 'testing/log/2021-w20.lit', 1, 1, 1 ],\n  [ 'testing/log/checkforinput.js', 1, 1, 1 ],\n  [ 'testing/log/today.js', 1, 1, 1 ],\n  [ 'testing/runkit-repl-endpoint.js', 1, 1, 1 ],\n  [ 'testing/runkit.lit', 1, 1, 1 ],\n  [ 'testing/serviceworker.lit', 1, 1, 1 ],\n  [ 'utils/momento.lit', 1, 1, 1 ] ]\n```\n\n\n\n```js\nconst fs = lit.lfs \nconst dir = lit.location.root\nconst git = lit.git\nconst FILE = 0, WORKDIR = 2, STAGE = 3\n\n// list files with unstaged changes\nreturn (async () => {\n  const filenames = (await git.statusMatrix({ fs,dir}))\n  .filter(row => row[WORKDIR] !== row[STAGE])\n  .map(row => row[FILE])\n  return filenames\n})()\n```\n```>txt attached=true updated=1621123864584\n[ '<', 'renderer/viewers', 'testing/isomorphic_git.lit' ]\n```\n### Add\n\n```js\n\nconst fs = lit.lfs\nconst dir = lit.location.root\n\nreturn (async ()=> {\n  return await lit.git.add({\n    fs,\n    dir,\n    filepath: '.'\n  })\n})()\n```\n```>txt attached=true updated=1621335127754\nundefined\n```\n\n\n\n### Commit\n\n```js\n\nconst fs = lit.lfs\nconst dir = lit.location.root\n\nreturn (async ()=> {\nconst now = (new Date()).toISOString()\nlet sha = await lit.git.commit({\n  fs,\n  dir,\n  message: `Auto commit (${now})`,\n  author: {\n    name: 'dotlit',\n    email: 'bit@dotlit.org'\n  }\n})\n\nconsole.log(sha)\n\n})()\n```\n```>txt attached=true updated=1619388707640\n2c1dcf840173cd7c36aa1e5b96bc0922006de579\nundefined\n```\n\n### Log\n\n```js > text !collapse\nconst indentLines = str => str.split('\\n').map( line => `      ${line}`).join('\\n')\n\nreturn (async ()=> {\n  let commits = await lit.git.log({\n     fs: lit.lfs, \n     dir: lit.location.root, \n     depth: 10\n  })\n  return \"**Log**\\n\" + commits.map( x => `1. **\\`${x.oid.slice(0,6)}\\`**\n\n${indentLines(x.commit.message)}`).join('\\n')\n})()\n```\n```>text !collapse attached=true updated=1620129831107\n**Log**\n1. **`d738da`**\n\n      Auto commit testing/isomorphic_git.lit\n      \n      at: 2021-04-26T08:25:54.893Z\n      includes the following 2 files:\n      - testing/isomorphic_git.lit\n      - utils/git-commit-all.js\n      \n1. **`498191`**\n\n      Auto commit testing/isomorphic_git.lit\n      \n      at: 2021-04-26T08:16:04.689Z\n      includes the following 5 files:\n      - 404.lit,- execute_code_cells.lit,- testing/.gitignore,- testing/isomorphic_git.lit,- testing/lightningfs.lit\n      \n1. **`ef8bee`**\n\n      Auto commit testing/isomorphic_git.lit\n      \n      at: 2021-04-25T23:25:46.517Z\n      includes the following 1 files:\n      - testing/isomorphic_git.lit\n      \n1. **`e146ec`**\n\n      Auto commit testing/isomorphic_git.lit\n      \n      at: (2021-04-25T23:25:04.262Z)\n      includes the following 1 files:\n      - testing/isomorphic_git.lit\n      \n1. **`ccc6f8`**\n\n      Auto commit testing/isomorphic_git.lit\n      at: (2021-04-25T22:41:55.195Z)\n      includes the following tk files...\n      \n1. **`d6a406`**\n\n      Auto commit (2021-04-25T22:35:27.239Z)\n      \n1. **`2c1dcf`**\n\n      Auto commit (2021-04-25T22:11:46.433Z)\n      \n1. **`769349`**\n\n      Auto commit (${now})\n      \n1. **`74737c`**\n\n      Commit All!!!\n      \n1. **`a90dc6`**\n\n      Commit All!!!\n      \n```\n\n### Diff\n\n```js\nconst {git, lfs} = lit\nreturn [git.walk, git.TREE]\n```\n```>txt attached=true updated=1620405199415\n[ [Function: walk], [Function: TREE] ]\n```\n```js !collapse\nreturn lit.git\n  const commitHash1 = '0c40ed746ebe53cf744d78191d0bbc2941537280'\n  const commitHash2 = 'b081f51cd27f54cf58915512006838d4eb67716b'\n  const git = lit.git\n  return git.walk({\n    lit.lfs,\n    lit.location.root,\n    trees: [git.TREE({ ref: commitHash1 }), git.TREE({ ref: commitHash2 })],\n    map: async function(filepath, [A, B]) {\n      return filepath\n    })\n  )}\n```\n```>txt attached=true updated=1620405076140 !error\nundefined\n```\n\n## Http client\n\n```js\n\nreturn (async fn =>{\n  const http = await import('https://unpkg.com/isomorphic-git/http/web/index.js')\n  return lit.git.getRemoteInfo({ http: http.default, url: 'https://github.com/isomorphic-git/isomorphic-git' })\n})()\n\n```\n```>txt attached=true updated=1621336307318\nundefined\n```\n\n## Web worker\n\n```>js gitworker.js\n/* eslint-env worker */\n/* globals LightningFS git MagicPortal GitHttp */\nimportScripts(\n  \"https://unpkg.com/@isomorphic-git/lightning-fs\",\n  \"https://unpkg.com/isomorphic-git@beta\",\n  \"https://unpkg.com/isomorphic-git@beta/http/web/index.umd.js\",\n  \"https://unpkg.com/magic-portal\"\n);\n\nlet fs = new LightningFS(\"fs\", { wipe: true });\nconst portal = new MagicPortal(self);\nself.addEventListener(\"message\", ({ data }) => console.log(data));\n\n(async () => {\n  let mainThread = await portal.get(\"mainThread\");\n  let dir = \"/\";\n  portal.set(\"workerThread\", {\n    setDir: async _dir => {\n      dir = _dir;\n    },\n    clone: async args => {\n      fs = new LightningFS(\"fs\", { wipe: true });\n      try{\n      return git.clone({\n        ...args,\n        fs,\n        http: GitHttp,\n        dir,\n        onProgress(evt) {\n          mainThread.progress(evt);\n        },\n        onMessage(msg) {\n          mainThread.print(msg);\n        },\n        onAuth(url) {\n          console.log(url);\n          return mainThread.fill(url);\n        },\n        onAuthFailure({ url, auth }) {\n          return mainThread.rejected({ url, auth });\n        }\n      });\n      } catch(err) {\n        mainThread.failure({message}=err)\n      }\n    },\n    listBranches: args => git.listBranches({ ...args, fs, dir }),\n    listFiles: args => git.listFiles({ ...args, fs, dir }),\n    log: args => git.log({ ...args, fs, dir })\n  });\n})();\n```\n\n```html #reference !collapse\n<div>\n  <input\n    id=\"repository\"\n    type=\"text\"\n    style=\"width: 50em\"\n    title=\"Tip: enter a private repo URL to see the credentialManager plugin prompt for a password.\",\n    value=\"https://github.com/isomorphic-git/isomorphic-git\",\n  />\n  <button type=\"button\" id=\"cloneButton\">Clone</button>\n</div>\n<div>\n  <progress id=\"progress\" value=\"0\"></progress>\n  <span id=\"progress-txt\" style=\"font-family: monospace;\"></span>\n</div>\n<output id=\"log\" style=\"white-space: pre; font-family: monospace;\"></output>\n\n<script src=\"https://unpkg.com/magic-portal\"></script>\n<script>\n  // alert(\"Running\")\n  const $ = id => document.getElementById(id);\n\n  let worker = new Worker(\"gitworker.js\");\n  const portal = new MagicPortal(worker);\n  worker.addEventListener(\"message\", ({ data }) => console.log(data));\n\n  const mainThread = {\n    async print(message) {\n      let text = $(\"log\").textContent;\n      if (message.endsWith(\"\\r\")) {\n        // overwrite last line\n        text = text.trim().replace(/.+$/, \"\");\n      }\n      text += message + \"\\n\";\n      $(\"log\").textContent = text;\n    },\n    async progress(evt) {\n      $(\"progress-txt\").textContent = evt.phase;\n      $(\"progress\").value = evt.total ? evt.loaded / evt.total : 0.5;\n      return;\n    },\n    async fill(url) {\n      let username = window.prompt(\"Username:\");\n      let password = window.prompt(\"Password:\");\n      return { username, password };\n    },\n    async rejected({ url, auth }) {\n      window.alert(\"Authentication rejected\");\n      return;\n    }\n  };\n  portal.set(\"mainThread\", mainThread, {\n    void: [\"print\", \"progress\", \"rejected\"]\n  });\n\n```\n\n```>script https://unpkg.com/magic-portal !below\nhttps://unpkg.com/magic-portal\n```\n\n```js\nreturn new Promise((resolve,reject) => {\n  let myWorker;\n  try {\n    myWorker = new Worker('gitworker.js')\n    myWorker.onmessage = (ev) => {\n      if (ev.data === 'done') resolve(ev.data)\n      else console.log(ev.data)\n    }\n    myWorker.onerror = (err) => {\n      resolve({msg: \"worker.onerror: \" + err.message + \" (\" + err.filename + \":\" + err.lineno + \")\", err, err},)\n    }\n  } catch(err) {\n    resolve({msg: \"Caught err\", err})\n  }\n  \n})\n```\n\n\n```js\n  // alert(\"Running\")\n  const $ = id => document.getElementById(id);\n\n  let worker = new Worker(\"gitworker.js\");\n  const portal = new MagicPortal(worker);\n  worker.addEventListener(\"message\", ({ data }) => console.log(data));\n\n  const mainThread = {\n    async print(message) {\n      console.log(message)\n    },\n    async progress(evt) {\n      console.log(evt.phase, evt.total ? evt.loaded / evt.total : 0.5)\n      return;\n    },\n    async fill(url) {\n      let username = window.prompt(\"Username:\");\n      let password = window.prompt(\"Password:\");\n      return { username, password };\n    },\n    async rejected({ url, auth }) {\n      window.alert(\"Authentication rejected\");\n      return;\n    }, \n    async failure({message}) {\n      alert(\"Failure: \", message)\n      return\n    },\n  }\n  portal.set(\"mainThread\", mainThread, {\n    void: [\"print\", \"progress\", \"rejected\", \"failure\"]\n  });\n\nasync function doCloneAndStuff() {\n    console.log(\"CLONE\");\n\n    await workerThread.setDir(\"/testing\");\n\n    await workerThread.clone({\n      corsProxy: \"https://cors.isomorphic-git.org\",\n      url: \"https://GitHub.com/dotlitdev/dotlit\"\n    });\n    console.log(\"CLONED!!\")\n\n    let branches = await workerThread.listBranches({ remote: \"origin\" });\n    console.log(\"BRANCHES:\\n\" + branches.map(b => `  ${b}`).join(\"\\n\"))\n\n    let files = await workerThread.listFiles({});\n    console.log(\"FILES:\\n\" + files.map(b => `  ${b}`).join(\"\\n\"))\n\n    let commits = await workerThread.log({});\n    console.log(\"LOG:\\n\" +\n      commits\n        .map(c => `  ${c.oid.slice(0, 7)}: ${c.commit.message}`)\n        .join(\"\\n\"))\n  }\n\n  return (async () => {\n    const workerThread = await portal.get(\"workerThread\");\n    window.workerThread = workerThread\n    window.worker = worker\n    console.log(workerThread)\n\n    console.log(\"ready\")\n    await doCloneAndStuff()\n\n    \n  })();\n```\n```>txt attached=true updated=1621342790497\ntrue\n```\n\n```js\nreturn workerThread.log({})\n```\n```>txt attached=true updated=1621343998003\n{ setDir: [Function],\n  clone: [Function],\n  listBranches: [Function],\n  listFiles: [Function],\n  log: [Function] }\n```\n\n\n\n\n\n","key":"contents"}]
1. [/testing/fuzzy_text_search.lit](/testing/fuzzy_text_search.lit) 
   �
      > [{"indices":[[1,4]],"value":"/testing/fuzzy_text_search.lit","key":"pathname"},{"indices":[[34,37],[2835,2838],[2877,2880],[4789,4792],[4887,4890],[4919,4922],[4964,4967],[4993,4996],[5073,5076],[5100,5103],[5136,5139],[5156,5159],[5492,5495],[5518,5521],[5552,5555],[5581,5584],[5618,5621],[5639,5642],[5668,5671],[5692,5695]],"value":"# Fuzzy text search\n\nRelated\n\n- [[testing/compact_manifest]]\n\n## Fuse.js\n\nhttps://fusejs.io/\n\nhttps://dev.to/noclat/using-fuse-js-with-react-to-build-an-advanced-search-with-highlighting-4b93\n\n```js !collapse #intro\nreturn (async (fn) => {\n  const { default: Fuse } = await import(\n    \"https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.esm.js\"\n  );\n  const manifest = await fetch(\"/manifest.json\").then((res) => res.json());\n  const fuse = new Fuse(manifest.nodes, {\n    includeScore: true,\n    keys: [\"title\", \"id\"],\n  });\n\n  // 3. Now search!\n  return fuse.search(\"../../..\",{limit:5});\n})();\n\n```\n```js !plugin !collapse type=repl of=search\nexport const repl = async (src, meta) => {\n  const t = Date.now();\n\n  const { default: Fuse } = await import(\n    \"https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.esm.js\"\n  );\n  // const manifest = await fetch(\"/manifest.json\").then((res) => res.json());\n\n  const fullLocal = await (async (fn) => {\n    const path = lit.utils.path;\n    const all = [];\n    const visit = async (root) => {\n      try {\n        const list = await lit.fs.readdir(root);\n        return Promise.all(\n          list.map(async (key) => {\n            const pathname = path.join(root, key);\n            const stat = await lit.fs.stat(pathname);\n            let contents;\n            if (key === \".git\" || !key) {\n            } else if (stat.type === \"dir\") await visit(pathname);\n            else if (pathname.endsWith(\".lit\"))\n              contents = await lit.fs.readFile(pathname, {\n                encoding: \"utf8\",\n                localOnly: true,\n              }); //.slice(0,10);\n            const item = { pathname, type: stat.type, contents };\n            all.push(item);\n            return item;\n          })\n        );\n      } catch (err) {\n        alert(err.message);\n      }\n    };\n\n    await visit(\"/\");\n    return all;\n  })();\n\n  // return fullLocal\n\n  const fuse = new Fuse(fullLocal, {\n    ignoreLocation: true,\n    includeScore: true,\n    includeMatches: true,\n    ignoreFieldNorm: true,\n    minMatchCharLength: 4,\n    keys: [\"pathname\", \"contents\"],\n  });\n\n  // 3. Now search!\n  const query = src.trim();\n  const msg = `Results for search \"**${query}**\". In **${\n    (Date.now() - t) / 1000\n  }** seconds.\\n\\n`;\n\n  return (\n    msg +\n    fuse\n      .search(query, { limit: 10 })\n      //.map(x=>x.matches.map(x=>x.indices))\n      .map((x) => [x.score, x.item.pathname, x.refIndex, x.matches])\n      .map(\n        ([score, pathname, index, matches]) =>\n          `1. [${pathname}](${pathname}) \n    \n      > ${JSON.stringify(matches)}`\n      )\n      .join(\"\\n\")\n  );\n};\n\n```\n```js search.jsx !plugin !collapse type=viewer Babel=true of=search2\nimport Fuse from \"https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.esm.js\";\nexport const viewer = ({ node, React }) => {\n\n  const {useEffect,useState} = React\n  const [msg, setMsg] = useState('Searching...')\n  // const manifest = await fetch(\"/manifest.json\").then((res) => res.json());\n\n  // Recursively builds JSX output adding `<mark>` tags around matches\n  const highlight = (value, indices = [], i = 1) => {\n    const pair = indices[indices.length - i];\n    return !pair ? (\n      value\n    ) : (\n      <>\n        {highlight(value.substring(0, pair[0]), indices, i + 1)}\n        <mark>{value.substring(pair[0], pair[1] + 1)}</mark>\n        {value.substring(pair[1] + 1)}\n      </>\n    );\n  };\n\n  const fullLocal = async (fn) => {\n    const path = lit.utils.path;\n    const all = [];\n    const visit = async (root) => {\n      try {\n        const list = await lit.fs.readdir(root);\n        return Promise.all(\n          list.map(async (key) => {\n            const pathname = path.join(root, key);\n            const stat = await lit.fs.stat(pathname);\n            let contents;\n            if (key === \".git\" || !key) {\n            } else if (stat.type === \"dir\") await visit(pathname);\n            else if (pathname.endsWith(\".lit\"))\n              contents = await lit.fs.readFile(pathname, {\n                encoding: \"utf8\",\n                localOnly: true,\n              }); //.slice(0,10);\n            const item = { pathname, type: stat.type, contents };\n            all.push(item);\n            return item;\n          })\n        );\n      } catch (err) {\n        alert(err.message);\n      }\n    };\n\n    await visit(\"/\");\n    return all;\n  };\n\n  // return fullLocal\n\n  useEffect(async fn => {\n     const t = Date.now();\nconst fuse = new Fuse(await fullLocal(), {\n    ignoreLocation: true,\n    includeScore: true,\n    includeMatches: true,\n    ignoreFieldNorm: true,\n    minMatchCharLength: 4,\n    keys: [\"pathname\", \"contents\"],\n  });\n\n  // 3. Now search!\n  const query = node.data.value.trim();\n\n  return (\n    <div>\n      <span>{msg}</span>\n    </div>\n  );\n};\n\n```\n\n\n\n```text repl=search\ntest\n```\n\n```>md updated=1621870142091\nResults for search \"**fuzz**\". In **0.074** seconds.\n\n1. [/testing/fuzzy_text_search.lit](/testing/fuzzy_text_search.lit) 0.000001\n1. [/testing/log/2021-05-23.lit](/testing/log/2021-05-23.lit) 0.001\n1. [/functions.lit](/functions.lit) 0.25\n1. [/testing/input_buffer.lit](/testing/input_buffer.lit) 0.25\n1. [/testing/full.json](/testing/full.json) 0.5\n1. [/utils/functions.js](/utils/functions.js) 0.5\n1. [/index.lit](/index.lit) 0.5\n1. [/execute_code_cells.lit](/execute_code_cells.lit) 0.5\n1. [/plugin_system.lit](/plugin_system.lit) 0.5\n1. [/scratch_pad.lit](/scratch_pad.lit) 0.5\n1. [/prismjs_and_a_simple_editor.lit](/prismjs_and_a_simple_editor.lit) 0.5\n1. [/testing/lightningfs.lit](/testing/lightningfs.lit) 0.5\n1. [/testing/isomorphic_git.lit](/testing/isomorphic_git.lit) 0.5\n1. [/testing/runkit.lit](/testing/runkit.lit) 0.5\n1. [/testing/selection.lit](/testing/selection.lit) 0.5\n```\n\n\n\n\n\n## FuzzySet\n\nhttps://github.com/Glench/fuzzyset.js\n\n```js\nreturn import('https://cdn.skypack.dev/fuzzyset').then( FuzzySet => {\n\n  const f = new FuzzySet.default()\n  f.add(\"the text of mine\")\n  f.add(\"the text of someone else\")\n  f.add(\"other texts\")\n  return f.get(\"text of\")\n})\n\n```\n```>txt attached=true updated=1621778112764\n[ [ 0.4375, 'the text of mine' ] ]\n```\n","key":"contents"}]
1. [/testing/serviceworker.lit](/testing/serviceworker.lit) 
   �
      > [{"indices":[[1,4]],"value":"/testing/serviceworker.lit","key":"pathname"},{"indices":[[752,755],[2204,2207],[2624,2627],[2838,2841],[4335,4338],[5924,5927]],"value":"# Service Worker\n\n```js exec=onload !collapse\nreturn fetch(\"--sw\")\n  .catch((err) => err.message)\n  .then((res) => res.text());\n\n```\n\n## Table of Contents\n\n## References \n\n- https://ponyfoo.com/articles/serviceworker-revolution\n- https://github.com/homam/service-workers-example\n- Communication \n  - ~[broadcast channels](https://stackoverflow.com/a/66784901/371040)~ not available in safari, desktop or iOS \n- Initial source, from: https://googlechrome.github.io/samples/service-worker/basic/\n- https://developer.mozilla.org/en-US/docs/Web/API/FetchEvent/respondWith\n- https://stackoverflow.com/questions/44424709/passing-state-info-into-a-service-worker-before-install\n- https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API/Using_Fetch\n\n\nSee [[testing/Web Workers]] for related investigation.\n\n## Exploration\n```js\nreturn navigator\n```\n```>txt attached=true updated=1619869271361\n{}\n```\n\n```js\nif ('serviceWorker' in navigator) {\n  return true\n}\n```\n```>txt attached=true updated=1619524117633\ntrue\n```\n\n\n```js #register\nreturn navigator\n          .serviceWorker\n          .register('/serviceworker.js?root='+lit.location.root)\n```\n```>txt attached=true updated=1621682807522\n{}\n```\n\n```js #status\nreturn navigator.serviceWorker.controller\n         ? \"Service worker active.\"\n         : \"Service worker Not active.\"\n```\n```>txt attached=true updated=1621861739207\nService worker active.\n```\n\n```js #unregister\nreturn (async fn => {\n  const regs = await navigator\n                     .serviceWorker\n                     .getRegistrations()\n  for(let registration of regs) {\n    console.log(registration)\n    registration.unregister()\n  }\n  return `Unregistered ${regs.length} regisration(s)`\n})()\n```\n```>txt attached=true updated=1621716614935\n{}\nUnregistered 1 regisration(s)\n```\n```js\nreturn fetch('/none')\n       .then( resp => resp.status )\n```\n```>txt attached=true updated=1620028398727\n404\n```\n```js\nreturn fetch('/manifest.json')\n       .then(resp => resp.status)\n```\n```>txt attached=true updated=1619884198845\n200\n```\n```js\nreturn (new Response('hello')).text()\n```\n```>txt attached=true updated=1619524123503\nhello\n```\n\nAs of now, the service worker doesn't cache anything and just passes through to the network as normal. Except if the `request.url` ends with `--sw` in which case it returns a mock/info response.\n```js\nreturn fetch('--sw')\n       .then(resp => resp.text()\n                          .then( text => `${resp.status}\\n${text}`)\n       )\n```\n```>txt attached=true updated=1621684367869\n200\n{\n  \"version\": \"0.2.8\",\n  \"dotlit\": \"object\",\n  \"root\": \"\",\n  \"enableCache\": false,\n  \"filepath\": \"/testing/\",\n  \"stat\": {\n    \"type\": \"dir\",\n    \"mode\": 511,\n    \"size\": 0,\n    \"ino\": 1,\n    \"mtimeMs\": 1621200461729,\n    \"ctimeMs\": 1621200461729,\n    \"uid\": 1,\n    \"gid\": 1,\n    \"dev\": 1\n  }\n}\n```\n\n\n```text < ./getserviceworker--sw \n\n```\n\n## Implementation\n\n```>js ../serviceworker.js !collapse #implementation\n// gross hack around one of @codemirror/view bugs\nlet document = { documentElement: { style: {} } };\n\nimportScripts(\"web.bundle.js\");\n\nconst state = {\n  version: \"0.2.12\",\n  dotlit: typeof dotlit,\n  root: \"\",\n  enableCache: false,\n};\n\nconst PRECACHE = \"precache-v1\";\nconst RUNTIME = \"runtime\";\n\n// A list of local resources we always want to be cached.\nconst PRECACHE_URLS = [\n  //'index.html',\n  //'./', // Alias for index.html\n  //'styles.css',\n  //'../../styles/main.css',\n  //'demo.js'\n];\n\nconst getMockResponse = async (event) => {\n  try {\n    if (typeof dotlit !== \"undefined\") {\n      const filepath = event.request.url\n        .slice(dotlit.lit.location.base.length - 1, -4)\n        .slice();\n      const stat = await dotlit.lit.fs.stat(filepath);\n      const status = {\n        ...state,\n        filepath,\n        stat,\n      };\n      return new Response(JSON.stringify(status, null, 2), {\n        headers: { meta: state.version },\n      });\n    }\n  } catch (err) {\n    const status = {\n      ...state,\n      url: event.request.url,\n      err: err.message,\n    };\n    return new Response(JSON.stringify(status, null, 2));\n  }\n};\n\nconst localFile = async (event) => {\n  if (typeof dotlit !== \"undefined\") {\n    const filepath = event.request.url\n      .slice(dotlit.lit.location.base.length - 1)\n      .slice();\n    await dotlit.lit.fs.stat(filepath);\n    let jsFile;\n    if (/.*\\.m?jsx?$/.test(filepath)) {\n      jsFile = true;\n    }\n    const content = await dotlit.lit.fs.readFile(filepath, { localOnly: true });\n    return new Response(content, {\n      headers: {\n        server: `dotlit.org/sw@${state.version}`,\n        jsFile: jsFile,\n        \"Content-Type\": jsFile ? \"text/javascript\" : \"text/plain\",\n      },\n    });\n  } else throw new Error(\"dotlit module not loaded.\");\n};\n\n// The install handler takes care of precaching the resources we always need.\nself.addEventListener(\"install\", (event) => {\n  state.root = new URL(location).searchParams.get(\"root\");\n  event.waitUntil(\n    caches\n      .open(PRECACHE)\n      .then((cache) => cache.addAll(PRECACHE_URLS))\n      .then(self.skipWaiting())\n  );\n});\n\n// The activate handler takes care of cleaning up old caches.\nself.addEventListener(\"activate\", (event) => {\n  const currentCaches = [PRECACHE, RUNTIME];\n  event.waitUntil(\n    caches\n      .keys()\n      .then((cacheNames) => {\n        return cacheNames.filter(\n          (cacheName) => !currentCaches.includes(cacheName)\n        );\n      })\n      .then((cachesToDelete) => {\n        return Promise.all(\n          cachesToDelete.map((cacheToDelete) => {\n            return caches.delete(cacheToDelete);\n          })\n        );\n      })\n      .then(() => self.clients.claim())\n  );\n});\n\n// The fetch handler serves responses for same-origin resources from a cache.\n// If no response is found, it populates the runtime cache with the response\n// from the network before returning it to the page.\nself.addEventListener(\"fetch\", (event) => {\n  // Skip cross-origin requests, like those for Google Analytics. And add mock response\n  if (event.request.url.startsWith(self.location.origin)) {\n    if (event.request.url.endsWith(\"--sw\")) {\n      console.log(\"Mock/Info request\");\n      event.respondWith(getMockResponse(event));\n    } else {\n      event.respondWith(\n        localFile(event)\n          .then((file) => {\n            console.log(\"Responding with\", file);\n            return file;\n          })\n          .catch((err) => {\n            console.log(\"Failed local file check, reverting to network\", err);\n            return caches.match(event.request).then((cachedResponse) => {\n              if (state.enableCache && cachedResponse) {\n                return cachedResponse;\n              }\n\n              return caches.open(RUNTIME).then((cache) => {\n                return fetch(event.request)\n                  .then((response) => {\n                    // Put a copy of the response in the runtime cache.\n                    return cache\n                      .put(event.request, response.clone())\n                      .then(() => {\n                        return response;\n                      });\n                  })\n                  .catch((err) => {\n                    if (!cachedResponse) throw err;\n                    return cachedResponse;\n                  });\n              });\n            });\n          })\n      );\n    }\n  }\n});\n\n```\n","key":"contents"}]
1. [/testing/importing_js_modules.lit](/testing/importing_js_modules.lit) 
   �
      > [{"indices":[[1,4]],"value":"/testing/importing_js_modules.lit","key":"pathname"},{"indices":[[763,766],[1594,1597],[3462,3465],[3501,3504],[4567,4570],[5713,5716],[6032,6035],[6130,6133],[6171,6174],[6471,6474],[6510,6513],[6550,6553],[6577,6580],[6593,6596],[6620,6623],[6858,6861],[7027,7030],[7089,7092],[7273,7276],[7412,7415],[7494,7497],[7700,7703],[7941,7944]],"value":"# Importing JS Modules\n\n## Table of Contents \n\n## References\n\n- https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Modules\n- https://github.com/WICG/import-maps\n- https://github.com/tc39/proposal-import-meta\n- https://v8.dev/features/modules\n- https://jakearchibald.com/2017/es-modules-in-browsers/\n\n```js #destructuring\nconst x = {\n  default: \"a\",\n  b: \"42\",\n  c: () => {},\n};\nconst { default: y, b: z } = x;\nreturn { y, z };\n\n```\n```>txt attached=true updated=1621550583088\n{ y: 'a', z: '42' }\n```\n\n## Skypack\n\n\n\n\n\n```js #skypack\nconst skypack = (pkg) => import(`https://cdn.skypack.dev/${pkg}`);\nreturn skypack(\"canvas-confetti\");\n\n```\n```>txt attached=true updated=1621634750440\n{ create: [Function: confettiCannon],\n  default: { [Function: fire] reset: [Function], create: [Function: confettiCannon] } }\n```\n```js #skypack\nconst skypack = (pkg) => import(`https://cdn.skypack.dev/${pkg}`);\n\nreturn skypack(\"canvas-confetti\").then((pkg) => {\n  const { default: fire } = pkg;\n  return fire();\n});\n\n```\n```>txt attached=true updated=1621551049304\nundefined\n```\n```js #skypack\nconst skypack = (pkg) => import(`https://cdn.skypack.dev/${pkg}`);\n\n// I like async await\nreturn (async (fn) => {\n  const { default: fire } = await skypack(\"canvas-confetti\");\n  return fire();\n})();\n\n```\n```>txt attached=true updated=1621551042809\nundefined\n```\n\n## Unpkg\n\n\n\n```js #unpkg\nconst unpkg = (pkg) => import(`https://unpkg.com/${pkg}?module`);\nreturn unpkg(\"canvas-confetti\");\n\n```\n```>txt attached=true updated=1621550434223\n{ create: [Function: confettiCannon],\n  default: { [Function: fire] reset: [Function], create: [Function: confettiCannon] } }\n```\n```js #unpkg\nconst unpkg = (pkg) => import(`https://unpkg.com/${pkg}?module`);\nreturn unpkg(\"canvas-confetti\").then((pkg) => {\n  return pkg.default();\n});\n\n```\n```>txt attached=true updated=1621583914027\nundefined\n```\n\n\n\n## Native ES Module REPL\n```>js ../plugins/repls/module.js !plugin type=repl of=module !collapse \nexport const repl = async (src, meta) => {\n  const { btoa } = lit.utils.safeEncoders;\n  const { transform } = lit.utils;\n  const filename = (meta && meta.filename) || \"untitled.js\";\n  let babel;\n  try {\n    babel = transform(filename, src);\n\n    // So many hacks due to blob and/or data uri\n    // - cachbusting comment\n    // - rewrite imports urls to be absolute\n    const s =\n      `/*${Date.now()}*/` +\n      babel.code.replace(\n        /HORRIBLE_HACK([^'\"]+)/g,\n        //location.href\n        new URL(\".\", location.href).toString() + \"$1\"\n      );\n    const console = \"fake me\";\n    // const url = `data:text/javascript;base64,${btoa(s)}`\n    const url = URL.createObjectURL(new Blob([s], { type: \"text/javascript\" }));\n    const m = await import(url + \"#location=\" + location.href);\n    if (typeof m.default === \"function\") {\n      const res = await m.default.call({ console });\n      return lit.utils.inspect(res);\n    } else return lit.utils.inspect(m);\n  } catch (err) {\n    return err.message;\n  }\n};\n\n```\n```js repl=module\nimport fire from \"https://cdn.skypack.dev/canvas-confetti\";\n\nexport const success = \"yes\";\nexport const issue =\n  \"module caching means it only executes once, had to add a cachebusting comment.\";\n\nexport default () => import.meta\nexport const cons = typeof console !== \"undefined\" ? console : null;\nfire();\n\n```\n```>txt attached=true updated=1621688470869\n{ url: 'blob:https://dotlit.org/f371b8d7-12a1-49d1-b9c6-ff6373727cf6#location=https://dotlit.org/testing/importing_js_modules.html?file=testing/importing_js_modules.lit#../plugins/repls/module.js' }\n```\n\n\n```js repl=module\nimport foo from '/notfound.js'\nexport default foo\n```\n```>txt attached=true updated=1621705508196\nModule name, '/notfound.js' does not resolve to a valid URL.\n```\n```>txt  updated=1621596754673\nModule name, '/notfound' does not resolve to a valid URL.\n```\n```>txt  updated=1621596671506\nModule specifier, 'notfound' does not start with \"/\", \"./\", or \"../\". Referenced from data:text/javascript;base64,LyoxNjIxNTk2NjcxNDkzKi9pbXBvcnQgZm9vIGZyb20gJ25vdGZvdW5kJzsKZXhwb3J0IGRlZmF1bHQgZm9vOw==\n```\n```js repl=module\nexport default async function (...args) {\n  return { args, console, ctx: this };\n};\n\n```\n```>txt attached=true updated=1621599908036\n{ args: [],\n  console: \n   { debug: [Function],\n     error: [Function],\n     log: [Function],\n     info: [Function],\n     warn: [Function],\n     clear: [Function],\n     dir: [Function],\n     dirxml: [Function: dirxml],\n     table: [Function],\n     trace: [Function: trace],\n     assert: [Function],\n     count: [Function],\n     countReset: [Function],\n     profile: [Function: profile],\n     profileEnd: [Function: profileEnd],\n     time: [Function],\n     timeLog: [Function],\n     timeEnd: [Function],\n     timeStamp: [Function: timeStamp],\n     takeHeapSnapshot: [Function: takeHeapSnapshot],\n     group: [Function],\n     groupCollapsed: [Function],\n     groupEnd: [Function],\n     record: [Function: record],\n     recordEnd: [Function: recordEnd],\n     screenshot: [Function: screenshot] },\n  ctx: { console: 'fake me' } }\n```\n\n```js repl=module\nexport default fn => console.screenshot(document.body)\n```\n```>txt attached=true updated=1621600683102\nundefined\n```\n\n```js repl=module\nconst { inspect } = lit.utils;\nconst { wait } = lit.utils.fns;\n\nexport default async (fn) => {\n  // https://github.com/whatwg/console/issues/120\n  console.record();\n  await wait(1000);\n  console.log(\"tick\", new Date());\n  await wait(1000);\n  console.log(\"tock\", new Date());\n  return console.recordEnd.toString();\n};\n\n```\n```>txt attached=true updated=1621600089887\n'function recordEnd() {\\n    [native code]\\n}'\n```\n\n## Local modules\n\nThis assumes you have the *experimental* service worker ([[testing/ServiceWorker]]) (version 0.2.10) enabled to vend files in the local filesystem via Web fetch API.\n\n```>js custom-module.mjs\nexport default (fn) => \"Great Success!\";\n\n```\n\n```js\nconst url = new URL(\"./foo\", location.href)\nreturn url.toString()\n```\n```>txt attached=true updated=1621688183147\nhttps://dotlit.org/testing/foo\n```\n\n```js repl=module\nimport foo from \"HORRIBLE_HACKcustom-module.mjs\";\nexport const test1 = \"HORRIBLE_HACKfoo\";\nexport const test2 = new URL(\"HORRIBLE_HACKcustom-module.mjs\").toString();\nexport const meta = import.meta;\nexport default foo();\n\n```\n```>txt attached=true updated=1621707123525\n{ default: 'Great Success!',\n  meta: { url: 'blob:https://dotlit.org/b269801f-a29f-49b2-9ebd-00ba04e7ad5b#location=https://dotlit.org/testing/importing_js_modules.html?file=testing/importing_js_modules.lit#' },\n  test1: 'https://dotlit.org/testing/foo',\n  test2: 'https://dotlit.org/testing/custom-module.mjs' }\n```\n\nThe correct resolution to the above hacks https://www.npmjs.com/package/babel-plugin-bare-import-rewrite\n```>txt  updated=1621690705217\n'Great Success!'\n```\n```>txt  updated=1621687020245\nModule name, './testing/custom-module.mjs' does not resolve to a valid URL.\n```\n```>txt  updated=1621686958336\n{ url: 'blob:https://dotlit.org/cda4db85-6121-4041-b417-46e4de9dfe08#path=testing/importing_js_modules.lit' }\n```\n\n```js\nreturn fetch('/testing/custom-module.mjs').then(res => res.headers.get('Content-Type'))\n```\n```>txt attached=true updated=1621686964618\ntext/javascript\n```\n\n\n- [x] ~Seems like `0.2.2` is *Still* not setting headers correctly, was expecting~ Got `text/javascript`.\n- [ ] fetch/sw now sends correct mime type, but still get `Module name, '/testing/custom-module.mjs' does not resolve to a valid URL.`\n```js\nreturn fetch('/testing/custom-module.mjs--sw').then(res => res.text())\n```\n```>txt attached=true updated=1621686173489\n{\n  \"version\": \"0.2.10\",\n  \"dotlit\": \"object\",\n  \"root\": \"/\",\n  \"enableCache\": false,\n  \"filepath\": \"/testing/custom-module.mjs\",\n  \"stat\": {\n    \"type\": \"file\",\n    \"mode\": 438,\n    \"size\": 41,\n    \"ino\": 198,\n    \"mtimeMs\": 1621634337946,\n    \"ctimeMs\": 1621634337946,\n    \"uid\": 1,\n    \"gid\": 1,\n    \"dev\": 1\n  }\n}\n```\n```js\nreturn fetch('/testing/custom-module.mjs').then(res => res.headers.get('server'))\n```\n```>txt attached=true updated=1621686224492\ndotlit.org/sw@0.2.10\n```\n\n\n- [x] ~After updating the service worker to return the correct mime type~, I suspect it's failing to resolve urls relative to the base64 data:uri setup. c.f. Original repl implementation which uses `createObjectURL`\n\n```js #extract\nconst esm = ({ raw }, ...vals) =>\n        URL.createObjectURL(\n          new Blob([String.raw({ raw }, ...vals)], { type: \"text/javascript\" })\n        );\n```\n\n\n\n\n\n\n\n\n\n\n\n\n","key":"contents"}]
1. [/testing/input_buffer.lit](/testing/input_buffer.lit) 
   �
      > [{"indices":[[1,4]],"value":"/testing/input_buffer.lit","key":"pathname"},{"indices":[[697,700],[1237,1240],[1300,1303],[1336,1339],[1372,1375],[2629,2632],[3292,3295],[3388,3391],[3516,3519],[3965,3968],[5536,5539]],"value":"# Input Buffer\n\n```js !collapse exec=onload !hidemeta < log/checkforinput.js > md !info\n// See implementation below for details\n```\n```>md !warn attached=true updated=1620722266322\n👀 *Checking for input...*\n```\n\n```js exec=onload !collapse !hidemeta < log/today.js > md !bigger\nconst date = new Date();\nconst isoDate = date.toISOString().split(\"T\")[0];\nconst today = isoDate;\nconst year = date.getFullYear();\nconst month = isoDate.split(\"-\").slice(0, -1).join(\"-\");\n\nconst firstDayOfYear = new Date(year, 0, 1);\nconst pastDaysOfYear = (date - firstDayOfYear) / 86400000;\nconst week = [\n  year,\n  \"w\" + Math.ceil((pastDaysOfYear + firstDayOfYear.getDay() + 1) / 7),\n].join(\"-\");\n\nconst prefix = `/testing/log/`;\nconst pathFor = (log) => `${prefix}${log}.lit`;\n\nconst checkForTodayFile = async () => {\n  let stat;\n  try {\n    stat = await lit.fs.readStat(pathFor(today));\n  } catch (err) {}\n  return `*Today* is [**${today}**](${pathFor(today)}), a log exists: *${\n    !!stat && !!(stat.local.stat || stat.remote.stat)\n  }*; See [week](${pathFor(week)}), [month](${pathFor(\n    month\n  )}) or [year](${pathFor(year)}).`;\n};\n\nreturn checkForTodayFile();\n\n```\n```>md !bigger attached=true updated=1621777505326\n*Today* is [**2021-05-23**](/testing/log/2021-05-23.lit), a log exists: *true*; See [week](/testing/log/2021-w22.lit), [month](/testing/log/2021-05.lit) or [year](/testing/log/2021.lit).\n```\n\n## Table of Contents\n\n## About\n\n*Inspired by [mymind](https://twitter.com/mymind) iOS app, [Blackbox](https://twitter.com/BlackboxPuzzles) iOS game and terrible iOS clipboards.*\n\n**aka:** [Peripheral](https://en.m.wikipedia.org/wiki/Peripheral), Input, AUX (Auxiliary)\n\n[![logo](https://www.electronics-tutorials.ws/wp-content/uploads/2013/08/log35.gif?fit=161%2C59)](https://www.electronics-tutorials.ws/logic/logic_9.html)\n\n> A peripheral or peripheral device is  an auxiliary device used to put information into and get information out of the computer.\n\n> peripheria, from Ancient Greek περιφέρεια (periphéreia, “the line around the circle, circumference, part of a circle, an arc, the outer surface”)\n\nUniversal ios sharesheet ~~app~~webapp, anything shared to the app is stored, catelogued, linked and editable, sortable, searchable and explorable offline in the app.\n\n> I'm prepared to wait as long as needed for Elon Musks NeuraLink to reach primetime but, We cant afford to sit around till then, we need incremental improvements of our Peripherals, over the Keyboard, Mouse and Touch Screens we have today.\n### Bookmarklet\n\n\n\n```js !inline viewer=bookmarklet id=Input !hidemeta\nwindow.location.href = \"https://dotlit.org/testing/input_buffer.html?input=\" + encodeURIComponent(\"- [ ] [\"+document.title+\"](\"+location.href+\")\")\n```\n### iOS shortcut\n\n[Lit 🔥 Input](https://www.icloud.com/shortcuts/7c5e088085e34d7d981aace463dcba51) an iOS shortcut which enables sending stuff from anywhere the iOS sharesheet is available, including highlighted text snippets etc, to this (your) Input Buffer.\n\n\n## Implementation\n\n### Bugs and Todos\n\n- [ ] `exec=onload` output is *still* buggy.\n- [ ] Search 🔍\n```js !collapse #mockinput > md\nconst qs = location.search.slice(1)\nreturn `Here's a [Mock Input](?${qs + (qs ? '&' : '')}input=${encodeURIComponent(\"- [ ] some **Input** \" + new Date())}) to test input capture.`\n```\n```>md attached=true updated=1621167143944\nHere's a [Mock Input](?file=testing/input_buffer.lit&input=-%20%5B%20%5D%20some%20**Input**%20Sun%20May%2016%202021%2013%3A12%3A23%20GMT%2B0100%20(BST)) to test input capture.\n```\n\n### Core\n\n\n```>js log/checkforinput.js !collapse\nconst date = new Date();\nconst isoDate = date.toISOString().split(\"T\")[0];\nconst today = isoDate;\nconst year = date.getFullYear();\nconst month = isoDate.split(\"-\")[1];\n\nconst firstDayOfYear = new Date(year, 0, 1);\nconst pastDaysOfYear = (date - firstDayOfYear) / 86400000;\nconst week = Math.ceil((pastDaysOfYear + firstDayOfYear.getDay() + 1) / 7);\n\nconst filename = (t) => `testing/log/${t}.lit`;\n\nconst checkForInput = async () => {\n  const insp = lit.utils.inspect;\n  const qs = lit.utils.querystring;\n\n  const search = location.search;\n  const query = search && qs.parse(search.slice(1));\n\n  if (query?.input) {\n    const input = query.input;\n    delete query.input;\n    const qsWoInput = qs.stringify(query);\n    window.history.replaceState(null, null, \"?\" + qsWoInput);\n\n    let stat = { local: {}, remote: {} };\n    try {\n      stat = await lit.fs.readStat(`/${filename(today)}`, { encoding: \"utf8\" });\n    } catch (err) {}\n    const newContent =\n      ((stat.local.stat && stat.local.value) ||\n        stat.remote.value ||\n        `# ${today}\n\nSee [week ${week}](/${filename(\n          year + \"-w\" + week\n        )}), [month ${month}](/${filename(\n          year + \"-\" + month\n        )}) or [year ${year}](/${filename(year)})\n`) +\n      (\"\\n\" + input);\n    await lit.fs.writeFile(`/${filename(today)}`, newContent);\n    return `***Captured Input (below) to [${today}](/${filename(today)})***\n\n${input}`;\n  } else {\n    return \"*No input detected.*\";\n  }\n};\nreturn checkForInput();\n\n```\n\n\n\n```>js log/today.js !collapse\nconst date = new Date();\nconst isoDate = date.toISOString().split(\"T\")[0];\nconst today = isoDate;\nconst year = date.getFullYear();\nconst month = isoDate.split(\"-\").slice(0, -1).join(\"-\");\n\nconst firstDayOfYear = new Date(year, 0, 1);\nconst pastDaysOfYear = (date - firstDayOfYear) / 86400000;\nconst week = [\n  year,\n  \"w\" + Math.ceil((pastDaysOfYear + firstDayOfYear.getDay() + 1) / 7),\n].join(\"-\");\n\nconst prefix = `/testing/log/`;\nconst pathFor = (log) => `${prefix}${log}.lit`;\n\nconst checkForTodayFile = async () => {\n  let stat;\n  try {\n    stat = await lit.fs.readStat(pathFor(today));\n  } catch (err) {}\n  return `*Today* is [**${today}**](${pathFor(today)}), a log exists: *${\n    !!stat && !!(stat.local.stat || stat.remote.stat)\n  }*; See [week](${pathFor(week)}), [month](${pathFor(\n    month\n  )}) or [year](${pathFor(year)}).`;\n};\n\nreturn checkForTodayFile();\n\n```\n\n```>html !below !collapse #styling\n<style>\n.dir-bigger {\n  font-size: 1.2em;\n}\n</style>\n```\n\n\n```lit !collapse #template < log/day.lit\n\n```\n```js !plugin !collapse type=viewer of=bookmarklet\nexport const viewer = ({ node, React }) => {\n  const rc = React.createElement;\n  const meta = node.properties.meta;\n  const href = `javascript:(function(){${node.data.value}})()`;\n  return rc(\"span\", null, [\n    \"Bookmarklet: \",\n    rc(\"a\", { href: href }, `Run ${meta && meta.id ? meta.id : \"bookmarklet\"}`),\n    \" href: \",\n    rc(\"pre\", null, rc(\"code\", null, href)),\n  ]);\n};\n\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","key":"contents"}]
1. [/testing/local_remote_files.lit](/testing/local_remote_files.lit) 
   �
      > [{"indices":[[1,4]],"value":"/testing/local_remote_files.lit","key":"pathname"},{"indices":[[110,113],[1076,1079],[1099,1102]],"value":"# Local and Remote files\n\nOn load `.lit` determines the `src` and `root` and checks both local file system ([[testing/LightningFS]]) and the remote host (ie GitHub pages, or local/remote server) and compares `last-updated` (or Stat `mtimeMs` in the case of local filesystem)\n\nThe problem is, that deployment to GitHub pages results in a remote file that *seems* newer than the local file that created it.\n\n## Potential solutions\n\n- Disable (appropriately) GitHub Pages cache\n\n  https://stackoverflow.com/questions/12556593/determining-a-page-is-outdated-on-github-pages\n- Read from api instead of pages static file server when Authenticated\n  - Potentially read and write to `gh-pages` directly, eschewing Actions deployment entirely.\n  - [x] Currently reading and writing to GitHub api when token is available. **Breaks reading generated files like : manifest.json**\n- Compare hashes of the content [stackoverflow crypto](https://stackoverflow.com/questions/18338890/are-there-any-sha-256-javascript-implementations-that-are-generally-considered-t/48161723#48161723)\n\n```txt test.txt remote=true < test.txt\nQ\n```\n```js\nreturn lit.fs.readFile('/manifest.json')\n```\n\n","key":"contents"}]
1. [/testing/autoformatting_cell_source.lit](/testing/autoformatting_cell_source.lit) 
   �
      > [{"indices":[[1,4]],"value":"/testing/autoformatting_cell_source.lit","key":"pathname"},{"indices":[[410,413]],"value":"# Autoformatting Cell Source\n## ... with prettier\n\nHomepage https://prettier.io\n\n```js babel=true #reference\nimport prettier from \"https://unpkg.com/prettier@2.3.0/esm/standalone.mjs\";\nimport parserBabel from \"https://unpkg.com/prettier@2.3.0/esm/parser-babel.mjs\";\n\nconsole.log(\n  prettier.format(\"const html=/* HTML */ `<DIV> </DIV>`\", {\n    parser: \"babel\",\n    plugins: [parserBabel],\n  })\n);\n\n```\n\n```js #test > js #formatted\nreturn (async fn => { // intentionally [sic] badly formatted \nconst p = await import(\n\n'https://unpkg.com/prettier@2.3.0/esm/standalone.mjs')\n           \n              const b = await \n          import('https://unpkg.com/prettier@2.3.0/esm/parser-babel.mjs')\nconst format \n= p.default.format\nconst babelPlugin \n= b.default\n\n\n  const thisCellsSource = this.children[0].children[0].data.value\n\n\nreturn format(thisCellsSource, { parser: \"babel\",plugins: [babelPlugin]})\n})()\n```\n```>js #formatted attached=true updated=1621285984079\nreturn (async (fn) => {\n  // intentionally [sic] badly formatted\n  const p = await import(\"https://unpkg.com/prettier@2.3.0/esm/standalone.mjs\");\n\n  const b = await import(\n    \"https://unpkg.com/prettier@2.3.0/esm/parser-babel.mjs\"\n  );\n  const format = p.default.format;\n  const babelPlugin = b.default;\n\n  const thisCellsSource = this.children[0].children[0].data.value;\n\n  return format(thisCellsSource, { parser: \"babel\", plugins: [babelPlugin] });\n})();\n\n```\n\nImplementing as a transformer `!plugin`\n\n```>js ../plugins/transformers/prettier.js !plugin type=transformer of=prettier id=prettier\nexport const transformer = async ({\n  node,\n  src,\n  codeSource,\n  rawSource,\n  originalSource,\n}) => {\n  const lines = src.split(\"\\n\");\n  let [first, ...rest] = lines;\n  let middle = rest.slice(0, -1);\n  const [last] = rest.slice(-1);\n  const body = middle.join(\"\\n\");\n\n  const p = await import(\"https://unpkg.com/prettier@2.3.0/esm/standalone.mjs\");\n  const b = await import(\n    \"https://unpkg.com/prettier@2.3.0/esm/parser-babel.mjs\"\n  );\n\n  const format = p.default.format;\n  const babelPlugin = b.default;\n  try {\n    return [\n      first,\n      format(body, { parser: \"babel\", plugins: [babelPlugin] }),\n      last,\n    ].join(\"\\n\");\n  } catch (err) {\n    lit.file.message(err.message);\n    return src;\n  }\n};\n\n```\n\n```js transformer=prettier\n// make me\n         // prettier\n//...\n                          // thanks\n\nreturn async fn=>{}\n\n```\n\nedit and save the above cell to have it automatically formatted by Prettier using the transformer `!plugin` implemented above.\n","key":"contents"}]
1. [/testing/runkit.lit](/testing/runkit.lit) 
   �
      > [{"indices":[[1,4]],"value":"/testing/runkit.lit","key":"pathname"},{"indices":[[2,5],[2154,2157],[2196,2199],[5130,5133],[5306,5309],[5573,5576]],"value":"# testing/runkit.lit\n\nExperimenting using [RunKit](https://runkit.com) as a custom repl for nodejs. Warning, it starts off messy, but in the end we have a reusable `nodejs` custom REPL.\n\n## Table of Contents\n\n## Embed\n\nLets start with just the simple [demo embed,](https://runkit.com/docs/embed) adding the embed script and a container below.\n\n```script https://embed.runkit.com !inline\n// injecting https://embed.runkit.com script\n```\n\n```html !inline\n<!-- anywhere else on your page -->\n<div id=\"my-element\">A container to hold the embed.</div>\n```\n\nRun the #init cell below 👇 to populate it With some demo source.\n\n\n\n```js #init !collapse\nreturn RunKit.createNotebook({\n    // the parent element for the new notebook\n    element: document.getElementById(\"my-element\"),\n    onEvaluate: (...args) => alert(JSON.stringify([...args])),\n    // specify the source of the notebook\n    source: \"// GeoJSON!\\nvar getJSON = require(\\\"async-get-json\\\");\\n\\nawait getJSON(\\\"https://storage.googleapis.com/maps-devrel/google.json\\\");\"\n})\n```\n\n\n## Endpoint\n\nreact bindings for simple embed: https://github.com/runkitdev/react-runkit and trying out https://runkit.com/docs/endpoint\n\n\n```jsx babel=true react=true repl=js !below #react #endpoint \nreturn (async fn => {\n\n  const React = lit.utils.React\n  const Embed = (await import('https://cdn.skypack.dev/runkit-embed-react')).default\n\n  const createdAt = new Date()\n\n  const helloSource = `exports.endpoint = function(request, response) {\n    response.end(\"Hello world! From .lit and Nodejs thanks to RunKit. Created at \" + createdAt);\n}`\n\n  const onLoad = (...args) => console.log(JSON.stringify([...args]))\n\n  return <Embed\n            mode='endpoint'\n            readOnly={true}\n            evaluateOnLoad={true}\n            // hidesActionButton={true}\n            source={ helloSource } \n            // ref='embed'\n            onLoad={ onLoad } \n          />\n\n})()\n```\n\n```uri !below\nhttps://2mkz0r1anfrl.runkit.sh/\n```\n## Viewer plug-in\n\n```jsx rk.jsx !collapse !plugin type=viewer of=runkit\nimport Embed from 'https://cdn.skypack.dev/runkit-embed-react'\n\nexport const viewer = ({node,React}) => {\n  const {useState} = React\n  const [url, setUrl] = useState(false)\n  const meta = node?.properties?.meta || {}\n  const endpoint = meta.attrs && meta.attrs.mode === 'endpoint'\n\n  const onLoad = async (rk) => {\n     if (endpoint)\n       setUrl(await rk.getEndpointURL())\n  }\n\n  return url || <Embed\n            mode={endpoint ? 'endpoint' : 'default'}\n            readOnly={endpoint}\n            evaluateOnLoad={endpoint}\n            hidesActionButton={endpoint}\n            source={ node.data.value } \n            // ref='embed'\n            onLoad={ onLoad } \n          />\n\n}\n```\n\n```runkit !inline\nconsole.log(\"Hello world! From .lit and Nodejs thanks to RunKit.\")\n```\n```runkit !below mode=endpoint\nexports.endpoint = function(req, res) {\n    res.end(\"Hello world! From .lit and Nodejs thanks to RunKit.\");\n}\n````\n```runkit !below mode=endpoint\nexports.endpoint = function(req,res) {\n  res.writeHead(200, {\n    'Content-Type': 'application/json',\n    'Access-Control-Allow-Origin': '*',\n    'Access-Control-Allow-Methods': '*',\n  });\n  res.end('{\"ping\": \"pong!\"}')\n}\n````\n\n```js\nreturn fetch(\"https://jzc0q8a4nyog.runkit.sh\").then(res => res.text())\n```\n```>txt attached=true updated=1621030315807\n{\"ping\": \"pong!\"}\n```\n\n## REPL endpoint plug-in `node`\n\nSplit out the endpoint source to its own `.lit` cell for legibility instead of an inline string.\n\n```>js runkit-repl-endpoint.js !collapse #source\nconst util = require('util')\n\nfunction requireFromString(src, filename) {\n  var Module = module.constructor;\n  var m = new Module();\n  m._compile(src, filename);\n  return m.exports;\n}\n\nexports.endpoint = function(req,res) {\n  res.writeHead(200, {\n    'Content-Type': 'application/json',\n    'Access-Control-Allow-Origin': '*',\n    'Access-Control-Allow-Methods': '*',\n  });\n\n  let data = '';\n  req.on('data', chunk => {\n    data += chunk;\n  })\n\n  req.on('end', async () => {\n    const payload = JSON.parse(data)\n    const exported = requireFromString(payload.src, payload.meta.filename || \"untitled.js\")\n    let result;\n    if (typeof exported === 'function') {\n      try {\n        result = await exported(payload.meta)\n        res.end(util.inspect({\n          result\n        }))\n      } catch(error) {\n        res.end(util.inspect({error}))\n      }\n    } else {\n      res.end(util.inspect({\n        exports: exported\n      }))\n    }\n  })\n}\n```\n\nOn load the following `repl` `!plugin` creates a RunKit endpoint if it doesn't exist using the above source.\n\n```js !plugin type=repl of=node !collapse\nif (typeof lit !== 'undefined' && !window.__runkitNodeEnpoint) {\n  (async fn => {\n    const el = document.createElement('div')\n    document.body.appendChild(el)\n    // el.setAttribute(\"style\", \"height:0;\")\n    RunKit.createNotebook({\n      element: el,\n      mode: 'endpoint',\n      onLoad: async (rk) => { \n        window.__runkitNodeEnpoint = await rk.getEndpointURL()\n        // document.body.removeChild(el)\n      },\n      evaluateOnLoad: true,\n      source: await lit.fs.readFile(\"testing/runkit-repl-endpoint.js\", {encoding: 'utf8'})\n    })\n  })()\n}\n\n\nexport const repl = async (src, meta, node) => {\n  if (!window.__runkitNodeEnpoint) {\n    return \"Still setting up repl endpoint\"\n  } else {\n    try {\n      return await (await fetch(window.__runkitNodeEnpoint, {\n        method: \"POST\",\n        body: JSON.stringify({src,meta})\n      })).text()\n    } catch(err) {\n      return err.message\n    }\n  }\n}\n```\n\n*Usage:*\n```js test.js repl=node\nmodule.exports = async (meta) => {\n  return `Hello world! From .lit and Nodejs ${process.env.NODE_VERSION} (${process.platform} ${process.arch}) thanks to RunKit. At ${new Date()}`\n}\n```\n```>txt attached=true updated=1621287964690\n{ result:\n   'Hello world! From .lit and Nodejs 10.24.1 (linux x64) thanks to RunKit. At Mon May 17 2021 21:46:04 GMT+0000 (Coordinated Universal Time)' }\n```\n```>txt  updated=1621086966109\n{ result:\n   'Hello world! From .lit and Nodejs 10.24.1 (linux x64) thanks to RunKit. At Sat May 15 2021 13:56:05 GMT+0000 (Coordinated Universal Time)' }\n```\n\n## Next steps and improvements\n\n- [ ] Don't start the endpoint on every page load, and instead lazily setup just before first execution.\n- [ ] Don't use require module from string hack, and instead use a proper `vm` abd context.","key":"contents"}]
1. [/testing/compact_manifest.lit](/testing/compact_manifest.lit) 
   �
      > [{"indices":[[1,4]],"value":"/testing/compact_manifest.lit","key":"pathname"},{"indices":[[594,597],[1027,1030],[1227,1230],[1296,1299]],"value":"# Compact Manifest\n\nReducing the serialised size of a manifest of all files in a `.lit` notebook.\n\n## Trying out [compact-prefix-tree](https://github.com/sidvishnoi/compact-prefix-tree)\n```js\nreturn (async fn => {\n  const {CompactPrefixTree} = await import('https://cdn.skypack.dev/compact-prefix-tree')\n\n  const manifest = await fetch('/manifest.json').then(res => res.json())\n  const keys = manifest.nodes.map(n=>n.id)\n  const trie = new CompactPrefixTree(keys)\n\n  const before = JSON.stringify(keys)\n  const after = JSON.stringify(trie.T)\n  // console.log(trie.T)\n  await lit.fs.writeFile('/testing/compactManifest1.json', after, 'utf8')\n  return `A ${after.length/before.length*100}% reduction in size.`\n})()\n```\n```>txt attached=true updated=1621379712347\nA 91.78470254957507% reduction in size.\n```\n\n\n\nLooking up a file, check for existence:\n```js\nreturn (async (fn) => {\n  const { CompactPrefixTree, getWordsFromTrie } = await import(\n    \"https://cdn.skypack.dev/compact-prefix-tree\"\n  );\n\n  const json = await fetch(\"/testing/compactManifest1.json\").then((res) =>\n    res.json()\n  );\n  // return json\n  const keys = getWordsFromTrie(json);\n  const trie = new CompactPrefixTree(Array.from(keys));\n  return trie.prefix(\"testing/log/\");\n})();\n\n```\n```>txt  updated=1621380328935\n{ prefix: 'testing/log/day.lit', isProper: true }\n```\n```>txt updated=1621380061074\n{ prefix: '', isProper: false }\n```\n","key":"contents"}]
```

```>md updated=1621870142091
Results for search "**fuzz**". In **0.074** seconds.

1. [/testing/fuzzy_text_search.lit](/testing/fuzzy_text_search.lit) 0.000001
1. [/testing/log/2021-05-23.lit](/testing/log/2021-05-23.lit) 0.001
1. [/functions.lit](/functions.lit) 0.25
1. [/testing/input_buffer.lit](/testing/input_buffer.lit) 0.25
1. [/testing/full.json](/testing/full.json) 0.5
1. [/utils/functions.js](/utils/functions.js) 0.5
1. [/index.lit](/index.lit) 0.5
1. [/execute_code_cells.lit](/execute_code_cells.lit) 0.5
1. [/plugin_system.lit](/plugin_system.lit) 0.5
1. [/scratch_pad.lit](/scratch_pad.lit) 0.5
1. [/prismjs_and_a_simple_editor.lit](/prismjs_and_a_simple_editor.lit) 0.5
1. [/testing/lightningfs.lit](/testing/lightningfs.lit) 0.5
1. [/testing/isomorphic_git.lit](/testing/isomorphic_git.lit) 0.5
1. [/testing/runkit.lit](/testing/runkit.lit) 0.5
1. [/testing/selection.lit](/testing/selection.lit) 0.5
```





## FuzzySet

https://github.com/Glench/fuzzyset.js

```js
return import('https://cdn.skypack.dev/fuzzyset').then( FuzzySet => {

  const f = new FuzzySet.default()
  f.add("the text of mine")
  f.add("the text of someone else")
  f.add("other texts")
  return f.get("text of")
})

```
```>txt attached=true updated=1621778112764
[ [ 0.4375, 'the text of mine' ] ]
```
